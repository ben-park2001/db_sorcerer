"""
RAG Agent - ê°œì„ ëœ ë²„ì „ (íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€ + ëª¨ë“œë³„ ìµœì í™”)
"""

import json
from typing import Dict, Any, List, Optional
from Models.llm import structured_LLM
from retriever import FileRetriever


class RAGAgent:
    """RAG ì‹œìŠ¤í…œì„ ì´ìš©í•œ ì—ì´ì „íŠ¸"""
    
    def __init__(self, mode: str = "deep", user_id: str = None):
        if not user_id:
            raise ValueError("ì‚¬ìš©ì IDê°€ í•„ìš”í•©ë‹ˆë‹¤. ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        self.mode = mode
        self.user_id = user_id
        self.max_iterations = self._get_max_iterations()
        self.retriever = FileRetriever(user_id=user_id)
        
        # ê°„ë‹¨í•˜ê³  ì•ˆì •ì ì¸ JSON ìŠ¤í‚¤ë§ˆ
        self.output_schema = {
            "type": "object",
            "properties": {
                "answer": {"type": "string"},
                "need_more": {"type": "boolean"},
                "next_query": {"type": "string"}
            },
            "required": ["answer", "need_more", "next_query"]
        }
    
    def _get_max_iterations(self) -> int:
        modes = {"normal": 1, "deep": 3, "deeper": 5}
        return modes.get(self.mode, 3)
    
    def process(self, user_input: str, conversation_history: Optional[List[Dict[str, str]]] = None) -> str:
        if conversation_history is None:
            conversation_history = []
            
        print(f"ğŸ¤– ì‚¬ìš©ì ì§ˆë¬¸: {user_input}")
        
        accumulated_context = ""
        last_search_results = []
        iteration = 0
        current_query = user_input
        
        while iteration < self.max_iterations:
            iteration += 1
            print(f"\nğŸ”„ ë°˜ë³µ {iteration}/{self.max_iterations}")
            
            # ê²€ìƒ‰ ìˆ˜í–‰
            print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {current_query}")
            search_results = self.retriever.search_chunks(current_query, top_n=3)
            last_search_results = search_results
            
            if search_results:
                # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                context_texts = [result['text'] for result in search_results]
                new_context = "\n".join(context_texts)
                accumulated_context += f"\n\n=== ê²€ìƒ‰ ê²°ê³¼ {iteration} ===\n{new_context}"
                print(f"âœ… {len(search_results)}ê°œ ë¬¸ì„œ ì¡°ê° ë°œê²¬")
            else:
                print("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            
            # LLM ì²˜ë¦¬
            is_final = (iteration == self.max_iterations)
            prompt = self._build_prompt(user_input, accumulated_context, iteration, is_final)
            
            try:
                response = structured_LLM(prompt, self.output_schema)
                result = json.loads(response)
                
                print(f"ğŸ§  AI ì‘ë‹µ: {result['answer']}")
                print(f"ğŸ”„ ê³„ì† ê²€ìƒ‰ í•„ìš”: {result['need_more']}")
                
                # Normal ëª¨ë“œë‚˜ ìµœì¢… ë°˜ë³µì´ê±°ë‚˜ ë” ì´ìƒ ê²€ìƒ‰ ë¶ˆí•„ìš”ì‹œ ì¢…ë£Œ
                if self.mode == "normal" or is_final or not result['need_more']:
                    print("âœ… ê²€ìƒ‰ ì™„ë£Œ")
                    self._show_referenced_chunks(last_search_results)
                    return result['answer']
                
                # ë‹¤ìŒ ê²€ìƒ‰ ì¿¼ë¦¬ ì„¤ì •
                current_query = result.get('next_query', '').strip() or user_input
                print(f"â¡ï¸ ë‹¤ìŒ ê²€ìƒ‰ ì¿¼ë¦¬: {current_query}")
                
            except Exception as e:
                print(f"âŒ LLM ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                if is_final:
                    return f"ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ì •ë³´: {accumulated_context[:500]}..."
                continue
        
        return "ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _build_prompt(self, user_input: str, context: str, iteration: int, is_final: bool) -> str:
        """ëª¨ë“œë³„ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ê¸°ë³¸ ì •ë³´
        base_info = f"""
ì‚¬ìš©ì ì§ˆë¬¸: {user_input}
í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´:
{context if context else "ì•„ì§ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}
"""
        
        # ëª¨ë“œë³„ ì§€ì¹¨
        if self.mode == "normal":
            instruction = """
ë¹ ë¥¸ ë‹µë³€ ëª¨ë“œì…ë‹ˆë‹¤. í˜„ì¬ ì •ë³´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
- answer: í•µì‹¬ì„ ë‹´ì€ ë‹µë³€
- need_more: ì´ í•­ëª©ì€ *ë°˜ë“œì‹œ* false ë¡œ ë‹µë³€
- next_query: "" ì´ í•­ëª©ì€ *ë°˜ë“œì‹œ* ë¹ˆ ë¬¸ìì—´ë¡œ ë‹µë³€
"""
        elif self.mode == "deep":
            if is_final:
                instruction = f"""
ë§ˆì§€ë§‰ ë‹¨ê³„({iteration}íšŒì°¨)ì…ë‹ˆë‹¤. ìˆ˜ì§‘ëœ ì •ë³´ë¡œ ìµœì¢… ë‹µë³€í•˜ì„¸ìš”.
- answer: ì¢…í•©ì ì¸ ìµœì¢… ë‹µë³€ ë˜ëŠ” "ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ ë‹µë³€ ì–´ë ¤ì›€" ëª…ì‹œ
- need_more: ì´ í•­ëª©ì€ *ë°˜ë“œì‹œ* false ë¡œ ë‹µë³€
- next_query: "" ì´ í•­ëª©ì€ *ë°˜ë“œì‹œ* ë¹ˆ ë¬¸ìì—´ë¡œ ë‹µë³€
"""
            else:
                instruction = f"""
ê· í˜•ì¡íŒ íƒìƒ‰ ëª¨ë“œ {iteration}íšŒì°¨ì…ë‹ˆë‹¤. ì •ë³´ê°€ ì¶©ë¶„í•œì§€ íŒë‹¨í•˜ì„¸ìš”.
- answer: í˜„ì¬ ë¶„ì„ ê²°ê³¼ë‚˜ ì¤‘ê°„ ë‹µë³€
- need_more: ë” ê²€ìƒ‰ì´ í•„ìš”í•˜ë©´ true, ì¶©ë¶„í•˜ë©´ false
- next_query: í•„ìš”ì‹œ ë‹¤ìŒ ê²€ìƒ‰ì–´, ë¶ˆí•„ìš”í•˜ë©´ ""
"""
        else:  # deeper
            strategies = {
                1: "ê¸°ì´ˆ ì •ë³´ ìˆ˜ì§‘",
                2: "ì„¸ë¶€ ì •ë³´ íƒìƒ‰", 
                3: "ë§¥ë½ ë° ë°°ê²½ í™•ì¥",
                4: "ë‹¤ê°ì  ê´€ì  í™•ë³´",
                5: "ì •ë³´ ê²€ì¦ ë° ì¢…í•©"
            }
            current_strategy = strategies.get(iteration, "ì¢…í•© ë¶„ì„")
            
            if is_final:
                instruction = f"""
ì‹¬ì¸µ ë¶„ì„ ìµœì¢… ë‹¨ê³„({iteration}íšŒì°¨)ì…ë‹ˆë‹¤. ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì™„ì „í•œ ë‹µë³€í•˜ì„¸ìš”.
- answer: ì‹¬ì¸µ ë¶„ì„ì„ í†µí•œ ì™„ì „í•œ ìµœì¢… ë‹µë³€
- need_more: false
- next_query: ""
"""
            else:
                instruction = f"""
ì‹¬ì¸µ ë¶„ì„ ëª¨ë“œ {iteration}íšŒì°¨ - {current_strategy}
í˜„ì¬ ë‹¨ê³„ ëª©í‘œì— ë§ê²Œ ì¶”ê°€ íƒìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨í•˜ì„¸ìš”.
- answer: í˜„ì¬ê¹Œì§€ì˜ ë¶„ì„ ë‚´ìš©
- need_more: ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ ë” í•„ìš”í•˜ë©´ true
- next_query: ë‹¤ìŒ ë‹¨ê³„ì— ë§ëŠ” ìƒˆë¡œìš´ ê´€ì ì˜ ê²€ìƒ‰ì–´
"""
        
        return base_info + "\n" + instruction + """

ì¤‘ìš”: ì˜¤ì§ ê²€ìƒ‰ëœ ì •ë³´ë§Œ ì‚¬ìš©í•˜ê³ , ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì‘ë‹µí•˜ì„¸ìš”."""
    
    def _show_referenced_chunks(self, chunks: list):
        if not chunks:
            return
            
        print(f"\nğŸ“š ì°¸ê³ í•œ ë¬¸ì„œ ({len(chunks)}ê°œ):")
        print("=" * 50)
        for i, chunk in enumerate(chunks, 1):
            if isinstance(chunk, dict):
                chunk_text = chunk.get('text', '')
                file_name = chunk.get('file_name', 'ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼')
                preview = chunk_text[:200] + "..." if len(chunk_text) > 200 else chunk_text
                print(f"{i}. ğŸ“„ {file_name}")
                print(f"   {preview}")
            else:
                # ì´ì „ ë²„ì „ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ë¬¸ìì—´ ì²˜ë¦¬ë„ ìœ ì§€
                preview = chunk[:200] + "..." if len(chunk) > 200 else chunk
                print(f"{i}. {preview}")
            print("-" * 30)
    
    def close(self):
        self.retriever.close()


def main():
    print("RAG Agent - ê²€ìƒ‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. normal - ë¹ ë¥¸ ê²€ìƒ‰ (1íšŒ)")
    print("2. deep - ì¼ë°˜ ê²€ìƒ‰ (3íšŒ, ê¸°ë³¸ê°’)")  
    print("3. deeper - ì‹¬í™” ê²€ìƒ‰ (5íšŒ)")
    
    mode_input = input("ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (1/2/3, ì—”í„°=ê¸°ë³¸ê°’): ").strip()
    mode_map = {"1": "normal", "2": "deep", "3": "deeper"}
    mode = mode_map.get(mode_input, "deep")
    
    user_id = input("ì‚¬ìš©ì IDë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if not user_id:
        print("âŒ ì‚¬ìš©ì IDê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    
    try:
        agent = RAGAgent(mode, user_id=user_id)
        print(f"ğŸš€ {mode} ëª¨ë“œë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        user_question = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        answer = agent.process(user_question)
        print(f"\nğŸ¯ ìµœì¢… ë‹µë³€:\n{answer}")
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        agent.close()


if __name__ == "__main__":
    main()