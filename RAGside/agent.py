"""
RAG Agent - ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ê³¼ AI ì¶”ë¡ ì„ ë°˜ë³µí•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì—ì´ì „íŠ¸
"""

import json
from typing import Dict, Any, List, Optional
from Models.llm import structured_LLM
from retriever import FileRetriever


class RAGAgent:
    """RAG ì‹œìŠ¤í…œì„ ì´ìš©í•œ ì—ì´ì „íŠ¸"""
    
    def __init__(self, mode: str = "deep", user_id: str = None):
        """
        Args:
            mode: ê²€ìƒ‰ ëª¨ë“œ ('normal': 1íšŒ, 'deep': 3íšŒ, 'deeper': 5íšŒ)
            user_id: ì‚¬ìš©ì ID (ê¶Œí•œ í™•ì¸ìš©, í•„ìˆ˜)
        """
        if not user_id:
            raise ValueError("ì‚¬ìš©ì IDê°€ í•„ìš”í•©ë‹ˆë‹¤. ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        self.mode = mode
        self.user_id = user_id
        self.max_iterations = self._get_max_iterations()
        self.retriever = FileRetriever(user_id=user_id)
        
        # structured LLMì„ ìœ„í•œ JSON ìŠ¤í‚¤ë§ˆ
        self.output_schema = {
            "type": "object",
            "properties": {
                "llm_output": {
                    "type": "string",
                    "description": "AIì˜ ì‘ë‹µì´ë‚˜ ìƒê°"
                },
                "continue_iterate": {
                    "type": "boolean", 
                    "description": "ë” ê²€ìƒ‰ì´ í•„ìš”í•œì§€ ì—¬ë¶€"
                },
                "search_query": {
                    "type": "string",
                    "description": "ë‹¤ìŒì— ê²€ìƒ‰í•  ì¿¼ë¦¬ (continue_iterateê°€ trueì¼ ë•Œë§Œ ì˜ë¯¸ìˆìŒ, falseì¼ ë•ŒëŠ” ë¹ˆ ë¬¸ìì—´)"
                }
            },
            "required": ["llm_output", "continue_iterate"],
            "additionalProperties": False
        }
    
    def _get_max_iterations(self) -> int:
        """ëª¨ë“œì— ë”°ë¥¸ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë°˜í™˜"""
        modes = {"normal": 1, "deep": 3, "deeper": 5}
        return modes.get(self.mode, 3)  # ì˜ëª»ëœ ê°’ì´ë©´ ê¸°ë³¸ê°’ 3
    
    def process(self, user_input: str, conversation_history: Optional[List[Dict[str, str]]] = None) -> str:
        """
        ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ë°˜í™˜
        
        Args:
            user_input: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­
            conversation_history: ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ (optional)
            
        Returns:
            ìµœì¢… AI ì‘ë‹µ
        """
        if conversation_history is None:
            conversation_history = []
            
        print(f"ğŸ¤– ì‚¬ìš©ì ì§ˆë¬¸: {user_input}")
        
        # ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ëˆ„ì 
        accumulated_context = ""
        last_search_results = []  # ë§ˆì§€ë§‰ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥
        iteration = 0
        
        # ì²« ë²ˆì§¸ ê²€ìƒ‰ ì¿¼ë¦¬ëŠ” ì‚¬ìš©ì ì…ë ¥ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        current_query = user_input
        
        while iteration < self.max_iterations:
            iteration += 1
            print(f"\nğŸ”„ ë°˜ë³µ {iteration}/{self.max_iterations}")
            
            # 1. í˜„ì¬ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
            print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {current_query}")
            search_results = self.retriever.search_chunks(current_query, top_n=3)
            last_search_results = search_results  # ë§ˆì§€ë§‰ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥
            
            if search_results:
                new_context = "\n".join(search_results)
                accumulated_context += f"\n\n=== ê²€ìƒ‰ ê²°ê³¼ {iteration} ===\n{new_context}"
                print(f"âœ… {len(search_results)}ê°œ ë¬¸ì„œ ì¡°ê° ë°œê²¬")
            else:
                print("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            
            # 2. LLMì—ê²Œ í˜„ì¬ ìƒí™©ì„ ì „ë‹¬í•˜ê³  ë‹¤ìŒ ì•¡ì…˜ ê²°ì • (ìµœì¢… ë°˜ë³µ ì—¬ë¶€ ì „ë‹¬)
            is_final_iteration = (iteration == self.max_iterations)
            prompt = self._build_prompt(user_input, accumulated_context, iteration, conversation_history, is_final_iteration)
            
            try:
                response = structured_LLM(prompt, self.output_schema)
                result = json.loads(response)
                
                print(f"ğŸ§  AI ì‘ë‹µ: {result['llm_output']}")
                print(f"ğŸ”„ ê³„ì† ê²€ìƒ‰ í•„ìš”: {result['continue_iterate']}")
                
                # Normal ëª¨ë“œëŠ” ì²« ê²€ìƒ‰ í›„ ë¬´ì¡°ê±´ ì¢…ë£Œ
                if self.mode == "normal":
                    print("âœ… Normal ëª¨ë“œ - ê²€ìƒ‰ ì™„ë£Œ")
                    self._show_referenced_chunks(last_search_results)
                    return result['llm_output']
                
                # ìµœì¢… ë°˜ë³µì´ê±°ë‚˜ ë” ì´ìƒ ê²€ìƒ‰í•˜ì§€ ì•Šê² ë‹¤ë©´ ì¢…ë£Œ
                if is_final_iteration or not result['continue_iterate']:
                    print("âœ… ê²€ìƒ‰ ì™„ë£Œ")
                    self._show_referenced_chunks(last_search_results)
                    return result['llm_output']
                
                # ë‹¤ìŒ ê²€ìƒ‰ ì¿¼ë¦¬ ì„¤ì •
                current_query = result.get('search_query', '').strip()
                if not current_query:
                    current_query = user_input
                print(f"â¡ï¸ ë‹¤ìŒ ê²€ìƒ‰ ì¿¼ë¦¬: {current_query}")
                
            except Exception as e:
                print(f"âŒ LLM ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                if is_final_iteration:
                    # ìµœì¢… ë°˜ë³µì—ì„œ ì‹¤íŒ¨í•œ ê²½ìš°, ìˆ˜ì§‘ëœ ì •ë³´ë¡œ ê°„ë‹¨í•œ ë‹µë³€ ì‹œë„
                    return f"ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤. ê²€ìƒ‰ëœ ì •ë³´: {accumulated_context[:500]}..."
                continue
        
        # ì´ ë¶€ë¶„ì€ ì‹¤í–‰ë˜ì§€ ì•Šì•„ì•¼ í•¨ (while ë£¨í”„ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨)
        return "ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _build_prompt(self, user_input: str, context: str, iteration: int, conversation_history: List[Dict[str, str]], is_final_iteration: bool = False) -> str:
        """ëª¨ë“œì— ë”°ë¼ ì ì ˆí•œ í”„ë¡¬í”„íŠ¸ ë¹Œë”ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
        
        if self.mode == "normal":
            # Normal ëª¨ë“œëŠ” ë°˜ë³µì´ ì—†ì§€ë§Œ, êµ¬ì¡° ì¼ê´€ì„±ì„ ìœ„í•´ is_final_iterationì„ ì „ë‹¬í•©ë‹ˆë‹¤.
            return self._build_normal_prompt(user_input, context, conversation_history)
        elif self.mode == "deep":
            return self._build_deep_prompt(user_input, context, iteration, conversation_history, is_final_iteration)
        elif self.mode == "deeper":
            return self._build_deeper_prompt(user_input, context, iteration, conversation_history, is_final_iteration)
        else: # ê¸°ë³¸ê°’ ì²˜ë¦¬
            return self._build_deep_prompt(user_input, context, iteration, conversation_history, is_final_iteration)
        
    def _build_normal_prompt(self, user_input: str, context: str, conversation_history: List[Dict[str, str]], is_final_iteration: bool = False) -> str:
        """
        Normal ëª¨ë“œìš© í”„ë¡¬í”„íŠ¸: ì‹ ì†í•˜ê³  ê°„ê²°í•œ ë‹µë³€ ìƒì„±ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.
        """
        history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in conversation_history[-3:]])
        
        return f"""
    ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

    [ëŒ€í™” íˆìŠ¤í† ë¦¬]
    {history_text}

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {user_input}

    [ê²€ìƒ‰ëœ ì •ë³´]
    {context if context else "ê²€ìƒ‰ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}

    **[Normal ëª¨ë“œ ì§€ì¹¨]**
    ì´ ëª¨ë“œëŠ” ì‹ ì†í•œ ë‹µë³€ì„ ìœ„í•´ 1íšŒ ê²€ìƒ‰ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    **[ì‘ë‹µ í˜•ì‹]**
    - `llm_output`: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ê°„ê²°í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
    - `continue_iterate`: ë°˜ë“œì‹œ `false`ë¡œ ì„¤ì •í•˜ì„¸ìš” (Normal ëª¨ë“œëŠ” ì¶”ê°€ ê²€ìƒ‰ì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤).
    - `search_query`: ìƒëµí•˜ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •í•˜ì„¸ìš” (Normal ëª¨ë“œì—ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤).

    **[ì¤‘ìš” ì›ì¹™]**
    - ì˜¤ì§ ìœ„ì— ì œì‹œëœ [ê²€ìƒ‰ëœ ì •ë³´]ë§Œì„ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
    - ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš° "ê²€ìƒ‰ëœ ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.
    - ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€ì„ ë³´ì™„í•˜ì§€ ë§ˆì„¸ìš”.
    """
    def _build_deep_prompt(self, user_input: str, context: str, iteration: int, conversation_history: List[Dict[str, str]], is_final_iteration: bool) -> str:
        """
        Deep ëª¨ë“œìš© í”„ë¡¬í”„íŠ¸: ê· í˜•ì¡íŒ íƒìƒ‰ê³¼ ë‹µë³€ í’ˆì§ˆ í™•ë³´ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.
        """
        history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in conversation_history[-5:]])
        
        if is_final_iteration:
            action_instruction = """
    **[ë§ˆì§€ë§‰ ë‹¨ê³„ ì§€ì¹¨]**
    ì´ë²ˆì´ ë§ˆì§€ë§‰ ê²€ìƒ‰ì…ë‹ˆë‹¤. ë” ì´ìƒì˜ ì •ë³´ ìˆ˜ì§‘ì€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.
    1. **ë¶„ì„**: í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”.
    2. **ì‹¤í–‰**: `continue_iterate`ë¥¼ `false`ë¡œ ì„¤ì •í•˜ê³ , ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:
       - **ì¶©ë¶„í•œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°**: `llm_output`ì— ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì™„ì „í•œ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
       - **ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš°**: `llm_output`ì— "ìˆ˜ì§‘ëœ ì •ë³´ë¡œëŠ” í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤."ë¼ê³  ëª…ì‹œí•˜ê³ , ì–´ë–¤ ì •ë³´ê°€ ë¶€ì¡±í•œì§€ ì„¤ëª…í•˜ì„¸ìš”.
    """
        else:
            action_instruction = f"""
    **[í˜„ì¬ ë‹¨ê³„({iteration}/{self.max_iterations}) ì§€ì¹¨]**
    1. **ë¶„ì„**: í˜„ì¬ ì •ë³´ê°€ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸°ì— ì¶©ë¶„í•œì§€, í˜¹ì€ ë‹µë³€ì˜ í’ˆì§ˆì„ ë†’ì´ê¸° ìœ„í•´ ì–´ë–¤ ì •ë³´ê°€ ë” í•„ìš”í•œì§€ ë¶„ì„í•˜ì„¸ìš”.
    2. **ì‹¤í–‰**:
       - **ì •ë³´ê°€ ì¶©ë¶„í•  ê²½ìš°**: `continue_iterate`ë¥¼ `false`ë¡œ ì„¤ì •í•˜ê³  `llm_output`ì— ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
       - **ì •ë³´ê°€ ë¶€ì¡±í•  ê²½ìš°**: `continue_iterate`ë¥¼ `true`ë¡œ ì„¤ì •í•˜ê³ , `llm_output`ì—ëŠ” ë‹¤ìŒ ê²€ìƒ‰ì´ í•„ìš”í•œ ì´ìœ ë¥¼, `search_query`ì—ëŠ” í˜„ì¬ ì •ë³´ì˜ ì•½ì ì„ ë³´ì™„í•  êµ¬ì²´ì ì¸ ë‹¤ìŒ ê²€ìƒ‰ì–´ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    """

        return f"""
    ë‹¹ì‹ ì€ ì²´ê³„ì ì¸ ë¶„ì„ì„ í†µí•´ í’ˆì§ˆ ë†’ì€ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

    [ëŒ€í™” íˆìŠ¤í† ë¦¬]
    {history_text}

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {user_input}

    [í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´]
    {context if context else "ì•„ì§ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}

    **[í•µì‹¬ ì›ì¹™]**
    - ìˆ˜ì§‘ëœ ì •ë³´ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ë³´ì™„í•˜ì§€ ë§ˆì„¸ìš”.
    - ì •ë³´ê°€ ë¶€ì¡±í•˜ë‹¤ë©´ ì†”ì§í•˜ê²Œ "ì •ë³´ê°€ ë¶€ì¡±í•˜ë‹¤"ê³  ë‹µë³€í•˜ì„¸ìš”.

    {action_instruction}
    """

    def _build_deeper_prompt(self, user_input: str, context: str, iteration: int, conversation_history: List[Dict[str, str]], is_final_iteration: bool) -> str:
        """
        Deeper ëª¨ë“œìš© í”„ë¡¬í”„íŠ¸: ë‹¤ê°ì ì´ê³  ì‹¬ì¸µì ì¸ ë¶„ì„ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.
        """
        history_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in conversation_history[-7:]])
        strategy = self._get_iteration_strategy(iteration)
        
        if is_final_iteration:
            action_instruction = """
    **[ìµœì¢… ì¢…í•© ë° ê²€ì¦ ì§€ì¹¨]**
    ì´ë²ˆì´ ë§ˆì§€ë§‰ ë‹¨ê³„ì…ë‹ˆë‹¤. ë” ì´ìƒì˜ ê²€ìƒ‰ì€ ì—†ìŠµë‹ˆë‹¤.
    1. **ë¶„ì„**: í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ê³ , ì´ ì •ë³´ë“¤ì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸°ì— ì¶©ë¶„í•œì§€ í‰ê°€í•˜ì„¸ìš”.
    2. **ì‹¤í–‰**: `continue_iterate`ë¥¼ `false`ë¡œ ì„¤ì •í•˜ê³ , ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:
       - **ì¶©ë¶„í•œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°**: ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì™„ì „í•˜ê³  ì •í™•í•œ ìµœì¢… ë‹µë³€ì„ `llm_output`ì— ì‘ì„±í•˜ì„¸ìš”.
       - **ì •ë³´ê°€ ë¶ˆì¶©ë¶„í•œ ê²½ìš°**: `llm_output`ì— "í˜„ì¬ ìˆ˜ì§‘ëœ ì •ë³´ë¡œëŠ” ì™„ì „í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤."ë¼ê³  ëª…ì‹œí•˜ê³ , ìˆ˜ì§‘ëœ ì •ë³´ì˜ í•œê³„ì™€ ë¶€ì¡±í•œ ë¶€ë¶„ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
    """
        else:
            action_instruction = f"""
    **[í˜„ì¬ ë‹¨ê³„({iteration}/{self.max_iterations}) ì‹¬ì¸µ ë¶„ì„ ì§€ì¹¨]**
    **ì´ë²ˆ ë‹¨ê³„ ëª©í‘œ**: {strategy}
    1. **ë¶„ì„**: ìœ„ ëª©í‘œì— ë”°ë¼ í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ì„¸ìš”. ì‚¬ìš©ìì˜ ìˆ¨ê²¨ì§„ ì˜ë„ë‚˜ ì§ˆë¬¸ì˜ ì—¬ëŸ¬ ì¸¡ë©´ì„ ê³ ë ¤í•˜ì—¬, ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ ì–´ë–¤ ì •ë³´ê°€ ë” í•„ìš”í•œì§€ ì‹ë³„í•˜ì„¸ìš”.
    2. **ì‹¤í–‰**:
       - **í˜„ì¬ ì •ë³´ë¡œ ì¶©ë¶„í•˜ê±°ë‚˜ ë” ì´ìƒ ì§„í–‰ì´ ë¬´ì˜ë¯¸í•˜ë‹¤ë©´**: `continue_iterate`ë¥¼ `false`ë¡œ ì„¤ì •í•˜ê³  `llm_output`ì— ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
       - **ì¶”ê°€ íƒìƒ‰ì´ í•„ìš”í•˜ë‹¤ë©´**: `continue_iterate`ë¥¼ `true`ë¡œ ì„¤ì •í•˜ê³ , `llm_output`ì—ëŠ” í˜„ì¬ê¹Œì§€ì˜ ë¶„ì„ ë‚´ìš©ê³¼ ë‹¤ìŒ íƒìƒ‰ì˜ í•„ìš”ì„±ì„, `search_query`ì—ëŠ” ì´ë²ˆ ë‹¨ê³„ ëª©í‘œì— ë§ëŠ” ìƒˆë¡œìš´ ê´€ì ì˜ ê²€ìƒ‰ì–´ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    """

        return f"""
    ë‹¹ì‹ ì€ í¬ê´„ì ì´ê³  ì‹¬ì¸µì ì¸ ë¶„ì„ì„ í†µí•´ ì™„ì „í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ AI ë¦¬ì„œì²˜ì…ë‹ˆë‹¤.

    [ëŒ€í™” íˆìŠ¤í† ë¦¬]
    {history_text}

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {user_input}

    [ëˆ„ì  ìˆ˜ì§‘ëœ ì •ë³´]
    {context if context else "ì•„ì§ ìˆ˜ì§‘ëœ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}

    **[í•µì‹¬ ì›ì¹™]**
    - ìˆ˜ì§‘ëœ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë¹ˆ ê³µê°„ì„ ì±„ìš°ì§€ ë§ˆì„¸ìš”.
    - ì •ë³´ê°€ ë¶ˆì¶©ë¶„í•˜ë©´ ê·¸ ì‚¬ì‹¤ì„ ëª…í™•íˆ ë°íˆê³  ì–´ë–¤ ì •ë³´ê°€ ë¶€ì¡±í•œì§€ ì„¤ëª…í•˜ì„¸ìš”.

    {action_instruction}
    """
    def _get_iteration_strategy(self, iteration: int) -> str:
        """Deeper ëª¨ë“œì˜ ë°˜ë³µ ë‹¨ê³„ë³„ ì „ëµ ê°€ì´ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        strategies = {
            1: "ê¸°ì´ˆ ì •ë³´ ìˆ˜ì§‘: ì§ˆë¬¸ì˜ í•µì‹¬ ê°œë…ê³¼ ê´€ë ¨ëœ ê¸°ë³¸ ì‚¬ì‹¤ì„ í™•ë³´í•©ë‹ˆë‹¤.",
            2: "ì„¸ë¶€ ì •ë³´ íƒìƒ‰: êµ¬ì²´ì ì¸ ì‚¬ë¡€, ë°ì´í„°, í†µê³„ ë“± ìƒì„¸ ë‚´ìš©ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.",
            3: "ë§¥ë½ ë° ë°°ê²½ í™•ì¥: ê´€ë ¨ ì—­ì‚¬, ë°°ê²½ ì§€ì‹, ì£¼ë³€ ë¶„ì•¼ ì •ë³´ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.",
            4: "ë‹¤ê°ì  ê´€ì  í™•ë³´: ìƒë°˜ëœ ì˜ê²¬, ë‹¤ë¥¸ ì‹œê°, ì „ë¬¸ê°€ ë¹„í‰ ë“±ì„ ì°¾ì•„ë´…ë‹ˆë‹¤.",
            5: "ì •ë³´ ê²€ì¦ ë° ì¢…í•©: ìˆ˜ì§‘ëœ ì •ë³´ë“¤ì˜ ì‹ ë¢°ì„±ì„ êµì°¨ í™•ì¸í•˜ê³  ìµœì¢… ë‹µë³€ì„ ìœ„í•œ ëˆ„ë½ëœ ë¶€ë¶„ì„ ë³´ì™„í•©ë‹ˆë‹¤."
        }
        return strategies.get(iteration, "ì¢…í•©ì ì¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
    def _show_referenced_chunks(self, chunks: list):
        """ë§ˆì§€ë§‰ì— ì°¸ê³ í•œ chunkë“¤ì„ í‘œì‹œ"""
        if not chunks:
            return
            
        print(f"\nğŸ“š ì°¸ê³ í•œ ë¬¸ì„œ ({len(chunks)}ê°œ):")
        print("=" * 50)
        for i, chunk in enumerate(chunks, 1):
            # chunk í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ í‘œì‹œ
            preview = chunk[:200] + "..." if len(chunk) > 200 else chunk
            print(f"{i}. {preview}")
            print("-" * 30)
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.retriever.close()


def main():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    print("RAG Agent - ê²€ìƒ‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. normal - ë¹ ë¥¸ ê²€ìƒ‰ (1íšŒ)")
    print("2. deep - ì¼ë°˜ ê²€ìƒ‰ (3íšŒ, ê¸°ë³¸ê°’)")
    print("3. deeper - ì‹¬í™” ê²€ìƒ‰ (5íšŒ)")
    
    mode_input = input("ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (1/2/3, ì—”í„°=ê¸°ë³¸ê°’): ").strip()
    mode_map = {"1": "normal", "2": "deep", "3": "deeper"}
    mode = mode_map.get(mode_input, "deep")
    
    # ì‚¬ìš©ì ID ì…ë ¥
    user_id = input("ì‚¬ìš©ì IDë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if not user_id:
        print("âŒ ì‚¬ìš©ì IDê°€ í•„ìš”í•©ë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    try:
        agent = RAGAgent(mode, user_id=user_id)
        print(f"ğŸš€ {mode} ëª¨ë“œë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        print(f"ğŸ‘¤ ì‚¬ìš©ì: {user_id}")
    except ValueError as e:
        print(f"âŒ {e}")
        return
    
    try:
        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        user_question = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        
        # ì²˜ë¦¬ ë° ê²°ê³¼ ì¶œë ¥
        answer = agent.process(user_question)
        print(f"\nğŸ¯ ìµœì¢… ë‹µë³€:\n{answer}")
        
    except KeyboardInterrupt:
        print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        agent.close()


if __name__ == "__main__":
    main()
